<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Samuel Bernard, Laurent Pujo-Menjouet" />
  <title>Elements of Maths</title>
  <style>
    html {
      line-height: 1.5;
      font-family: Georgia, serif;
      font-size: 20px;
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 1em;
      }
    }
    @media print {
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, 'Lucida Console', Consolas, monospace;
      font-size: 85%;
      margin: 0;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      background-color: #1a1a1a;
      border: none;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    span.underline{text-decoration: underline;}
    div.column{display: inline-block; vertical-align: top; width: 50%;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
  </style>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
  
  
  
  
</head>
<body>
<header id="title-block-header">
<h1 class="title">Elements of Maths</h1>
<p class="subtitle">Math Fundamentals – INSA Lyon</p>
<p class="author">Samuel Bernard<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>, Laurent Pujo-Menjouet<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a></p>
<p class="date">Fall 2021</p>
</header>
<hr />
<p>Content</p>
<ul>
<li><p>Etude de fonctions</p></li>
<li><p>Dérivées de fonctions, dérivées de fonctions composées</p></li>
<li><p>Intégration: calcul des primitives, méthode de décompositions de fractions en éléments simples</p></li>
<li><p>Résolution d’EDO linéaires dimension 1</p></li>
<li><p>classification des EDO (linéaires, ordre, autonomes, …)</p></li>
<li><p>Théorème de Cauchy-Lipschitz</p></li>
<li><p>Linéarisation</p></li>
<li><p>Linéarisation d’une fonction de 2 variables (matrice jacobienne)</p></li>
<li><p>Exponentielle de matrice</p></li>
<li><p>Résolution de systèmes linéaires</p></li>
<li><p>Résolution d’EDO linéaires dimension 2</p></li>
</ul>
<p><a href="#complex-numbers">Complex numbers</a></p>
<ul>
<li><a href="#exercises-on-complex-numbers">Exercises on complex numbers</a></li>
</ul>
<p><a href="#matrices-in-dimension-two">Matrices in dimension two</a></p>
<ul>
<li><a href="#matrix-vector-operations">Matrix-vector operations</a>
<ul>
<li><a href="#exercises-on-matrix-vector-and-matrix-matrix-operations">Exercises on Matrix-vector and matrix-matrix operations</a></li>
</ul></li>
<li><a href="#eigenvalues-of-a-2x2-matrix">Eigenvalues of a 2x2 matrix</a>
<ul>
<li><a href="#exercises-on-eigenvalues">Exercises on eigenvalues</a></li>
</ul></li>
<li><a href="#eigenvalue-decomposition">Eigenvalue decomposition</a></li>
<li><a href="#eigenvectors">Eigenvectors</a>
<ul>
<li><a href="#example-1-distinct-real-eigenvalues">Example 1 Distinct, real eigenvalues</a></li>
<li><a href="#example-2-complex-eigenvalues">Example 2 Complex eigenvalues</a></li>
<li><a href="#example-3-repeated-eigenvalues-1">Example 3 Repeated eigenvalues 1</a></li>
<li><a href="#example-4-repeated-eigenvalues-2">Example 4 Repeated eigenvalues 2</a></li>
</ul></li>
<li><a href="#exercises-on-eigenvalues-decomposition">Exercises on eigenvalues decomposition</a></li>
</ul>
<p><a href="#glossary">Glossary</a></p>
<h1 id="complex-numbers">Complex numbers</h1>
<p>A complex number is a number that can be expressed in the form <span class="math inline">\(a + i b\)</span>, where <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span> are real numbers, and the symbol <span class="math inline">\(i\)</span> is called <strong>imaginary unit</strong>. The imaginary unit satisfies the equation <span class="math inline">\(i^2 = -1\)</span>. Because no real number satisfies this equation, this number is call <em>imaginary</em>.</p>
<p>For the complex number <span class="math inline">\(z = a + i b\)</span>, <span class="math inline">\(a\)</span> is called the <strong>real part</strong> and <span class="math inline">\(b\)</span> is called the <strong>imaginary part</strong>. The real part of <span class="math inline">\(z\)</span> is denoted <span class="math inline">\(\Re(z)\)</span> (<code>\Re</code> in LaTeX) or just <span class="math inline">\(\mathrm{Re}(z).\)</span> The imaginary part of <span class="math inline">\(z\)</span> denoted <span class="math inline">\(\Im(z)\)</span> (<code>\Im</code> in LaTex) or just <span class="math inline">\(\mathrm{Im}(z)\)</span>. The set of all complex numbers is denoted <span class="math inline">\(\mathbb{C}\)</span> (<code>\mathbb{C}</code> in LaTeX).</p>
<p>We need complex numbers for solving polynomial equations. The fundamental theorem of algebra asserts that a polynomial equation of with real or complex coefficients has complex solutions. These polynomial equations arise when trying to compute the eigenvalues of matrices, something we need to do to solve linear differential equations for instance.</p>
<p>Arithmetic rules that apply on real numbers also apply on complex numbers, by using the rule <span class="math inline">\(i^2 = -1\)</span>: addition, subtraction, multiplication and division are associative, commutative and distributive.</p>
<p>Let <span class="math inline">\(u = a + i b\)</span> and <span class="math inline">\(v = c + i d\)</span> two complex numbers, with real coefficients <span class="math inline">\(a,b,c,d\)</span>. Then</p>
<ul>
<li><p><span class="math inline">\(u + v = a + i b + c + i d = (a+c) + i (b+d)\)</span>.</p></li>
<li><p><span class="math inline">\(uv = (a + i b)(c + i d) = ac + i a d + i b c + i^2 b d = ac - bd + i(ad + bc)\)</span>.</p></li>
<li><p><span class="math inline">\(\frac{1}{v} = \frac{1}{c + i d} = \frac{c - id}{(c - id)(c + id)} = \frac{c - id}{c^2 + d^2} = \frac{c}{c^2 + d^2} - i \frac{d}{c^2+d^2}\)</span>.</p></li>
<li><p><span class="math inline">\(u = v\)</span> if and only if <span class="math inline">\(a = c\)</span> and <span class="math inline">\(b = d\)</span>.</p></li>
</ul>
<p>It follows from the rule on <span class="math inline">\(i\)</span> that</p>
<ul>
<li><span class="math inline">\(\frac 1i = -i.\)</span> (Proof: <span class="math inline">\(\frac 1i = \frac{i}{i^2} = \frac{i}{-1} = -i\)</span>.)</li>
</ul>
<p>Multiplying by the imaginary unit <span class="math inline">\(i\)</span> is equivalent to a counterclockwise rotation by <span class="math inline">\(\pi/2\)</span></p>
<p><span class="math display">\[ui = (a + ib)i = ia + i^2 b = -b + ia.\]</span></p>
<p>Let <span class="math inline">\(z = a + ib\)</span> a complex number with real <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span>. The <strong>conjugate</strong> of <span class="math inline">\(z\)</span>, denoted <span class="math inline">\(\bar z\)</span>, is <span class="math inline">\(a - ib\)</span>. The conjugate of the conjugate of <span class="math inline">\(z\)</span> is <span class="math inline">\(z\)</span> (<em>reflection</em>). The <strong>modulus</strong> of <span class="math inline">\(z\)</span>, denoted <span class="math inline">\(|z|\)</span> is <span class="math inline">\(\sqrt{z \bar z}\)</span>. The product <span class="math inline">\(z \bar z = (a+ib)(a-ib)=a^2 + b^2 + i(-ab + ab) = a^2 + b^2\)</span>. The modulus is the complex version of the absolute value, for if <span class="math inline">\(z\)</span> (i.e. <span class="math inline">\(b = 0\)</span>), <span class="math inline">\(|z| = \sqrt{a^2} = |a|\)</span>. It is always a real, positive number, and <span class="math inline">\(|z| = 0\)</span> if and only if <span class="math inline">\(z = 0\)</span>. The modulus also has the property of being the <em>length</em> of the complex number <span class="math inline">\(z\)</span>, if <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span> are the sides of a rectangular triangle, then <span class="math inline">\(|z|\)</span> is the hypotenuse</p>
<p>When simplifying a ratio involving a complex <span class="math inline">\(v\)</span> at the denominator, it is important to convert it to a real number by multiplying the ratio by <span class="math inline">\(\bar v/ \bar v\)</span>. For instance, if <span class="math inline">\(v =\neq 0\)</span>,</p>
<p><span class="math display">\[\frac{u}{v} = \frac{u \bar v}{u \bar v} = \frac{u \bar v}{|v|^2}.\]</span></p>
<p>The denominator <span class="math inline">\(|v|^2\)</span> is always a positive real number.</p>
<p>By allowing complex values, nonlinear functions of real numbers like exponentials, logarithms and trigonometric functions can have their domain extended to all real and complex numbers. The most useful extension is the exponential function. Recall that the exponential function <span class="math inline">\(e^x\)</span>, where <span class="math inline">\(e \approx 2.71828\)</span> is Euler’s constant, satisfies the relation <span class="math inline">\(e^{x + y} = e^{x} e^{y}\)</span>. This remains true for complex numbers. The <strong>Euler’s formula</strong> relates the exponential of a imaginary number with trigonometric functions. For a real number <span class="math inline">\(y\)</span>,</p>
<p><span class="math display">\[e^{i y} = \cos(y) + i \sin(y).\]</span></p>
<p>Therefore, for any complex number <span class="math inline">\(z = a + i b\)</span>, the exponential</p>
<p><span class="math display">\[e^{z} = e^{a + ib} = e^a e^{ib} = e^a \bigl( \cos(b) + i \sin(b) \bigr).\]</span></p>
<hr />
<p><strong>Tips on complex numbers</strong></p>
<ul>
<li><p>If <span class="math inline">\(x\)</span> is real, <span class="math inline">\(ix\)</span> is pure imaginary. If <span class="math inline">\(y\)</span> is imaginary, <span class="math inline">\(iy\)</span> is real.</p></li>
<li><p><span class="math inline">\(|i| = 1\)</span>. For any real <span class="math inline">\(\theta\)</span>, <span class="math inline">\(|e^{i \theta}| = 1\)</span>.</p></li>
<li><p><span class="math inline">\(|z_1 z_2| = |z_1| |z_2\)</span>.</p></li>
<li><p>In particular, <span class="math inline">\(|iz| = |i||z| = |z|\)</span>. (Multpliying by <span class="math inline">\(i\)</span> is a rotation in the complex plane, it does not change the modulus.)</p></li>
</ul>
<hr />
<h2 id="exercises-on-complex-numbers">Exercises on complex numbers</h2>
<p><strong>Exercise 1</strong> Let the complex number <span class="math inline">\(z = 2 + 3 i\)</span>. Compute</p>
<ul>
<li><p><span class="math inline">\(\bar z\)</span></p></li>
<li><p><span class="math inline">\(|z|\)</span></p></li>
<li><p><span class="math inline">\(|\bar z|\)</span> (compare with <span class="math inline">\(|z|\)</span>)</p></li>
<li><p><span class="math inline">\(z^2\)</span></p></li>
<li><p><span class="math inline">\(\Re(\bar z)\)</span></p></li>
<li><p><span class="math inline">\(\Im(\bar z)\)</span></p></li>
<li><p><span class="math inline">\(\frac{z + \bar z}{2}\)</span></p></li>
<li><p><span class="math inline">\(\frac{z - \bar z}{2}\)</span></p></li>
<li><p><span class="math inline">\(-z\)</span></p></li>
<li><p><span class="math inline">\(iz\)</span></p></li>
</ul>
<p><strong>Exercise 2</strong> Let the complex number <span class="math inline">\(z = a + ib\)</span> with real <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span>. Compute</p>
<ul>
<li><span class="math inline">\(\sqrt{z}\)</span> (<em>that is, express <span class="math inline">\(s = \sqrt{z}\)</span> as <span class="math inline">\(s = \alpha + i \beta\)</span>, with real <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span></em>)</li>
</ul>
<p><strong>Exercise 3</strong> A complex number is in <strong>polar form</strong> if it is expressed by the relation <span class="math inline">\(z = r ( \cos(\theta) + i \sin(\theta) )\)</span>.</p>
<ul>
<li><p>Show that <span class="math inline">\(|z| = r\)</span></p></li>
<li><p>Show that <span class="math inline">\(z = r e^{i \theta}\)</span></p></li>
<li><p>Conclude that for any complex number <span class="math inline">\(z\)</span>, <span class="math inline">\(|z| = 1\)</span> if and only if <span class="math inline">\(z\)</span> can be expressed as <span class="math inline">\(z = e^{i \theta}\)</span> for a real <span class="math inline">\(\theta\)</span>.</p></li>
</ul>
<p><strong>Exercise 4</strong> Using Euler’s formula, show that <span class="math inline">\(\cos(a)\cos(b) - \sin(a)\sin(b) = \cos(a+b)\)</span>.<br />
<em>(Use the property that <span class="math inline">\(e^{ia + ib} = e^{ia} e^{ib}\)</span> and apply Euler’s Formula)</em>.</p>
<p><strong>Exercise 5</strong> Show Euler’s identity: <span class="math inline">\(e^{i \pi} = -1\)</span>.</p>
<p><strong>Exercise 6</strong> For a complex <span class="math inline">\(z\)</span>, find necessary and sufficient conditions for <span class="math inline">\(e^{z t}\)</span>, <span class="math inline">\(t &gt; 0\)</span>, to converge to 0.</p>
<h1 id="matrices-in-dimension-two">Matrices in dimension two</h1>
<h2 id="eigenvalues-of-a-2x2-matrix">Eigenvalues of a 2x2 matrix</h2>
<p>A 2x2 matrix <span class="math inline">\(A\)</span> is an array with 2 rows and 2 columns: <span class="math display">\[A = \begin{pmatrix}
a &amp; b \\
c &amp; d 
\end{pmatrix},
\]</span> Usually, the <strong>coefficients</strong> <span class="math inline">\(a, b, c, d\)</span> are real numbers. The <span class="math inline">\(identity\)</span> matrix is the matrix <span class="math display">\[I = \begin{pmatrix}
1 &amp; 0 \\
0 &amp; 1 
\end{pmatrix},
\]</span></p>
<p>The <strong>determinant</strong> of <span class="math inline">\(A\)</span>, denoted <span class="math inline">\(\det A\)</span> or <span class="math inline">\(|A|\)</span> is the number <span class="math inline">\(ad - bc\)</span>. The <strong>trace</strong> of <span class="math inline">\(A\)</span>, denoted <span class="math inline">\(\mathrm{tr}\, A\)</span>, is the sum of the main <strong>diagonal</strong> of <span class="math inline">\(A\)</span>: <span class="math inline">\(a + d\)</span>.</p>
<p>The <strong>characteristic polynomial</strong> of <span class="math inline">\(A\)</span> is the second order polynomial in <span class="math inline">\(\lambda\)</span> obtained by computing the determinant of the matrix <span class="math inline">\(A - \lambda I\)</span>,</p>
<p><span class="math display">\[ \det ( A - \lambda I ) = (a-\lambda)(d-\lambda) - bc = ad - bc - \lambda ( a + d ) + \lambda^2.\]</span></p>
<p>The characteristic polynomial <span class="math inline">\(p_A(\lambda)\)</span> of <span class="math inline">\(A\)</span> can be expressed in terms of its determinant and trace:</p>
<p><span class="math display">\[p_A(\lambda) = \det A - \mathrm{tr}\, A \lambda + \lambda^2.\]</span></p>
<p>The <strong>eigenvalues</strong> of <span class="math inline">\(A\)</span> are the roots of the characteristic polynomial. By the fundamental theorem of algebra, we know that the characteristic polynomial has exactly two roots, counting multiple roots. These roots can be real, or complex. The eigenvalues of <span class="math inline">\(A\)</span> are calculated using the quadratic formula:</p>
<p><span class="math display">\[\lambda_{1,2} = \frac{1}{2} \Bigl( \mathrm{tr}\, A \pm \sqrt{ (\mathrm{tr}\, A)^2 - 4 \det A } \Bigr).\]</span></p>
<p>From this formula, we can classify the eigenvalues of <span class="math inline">\(A\)</span>. Let</p>
<p><span class="math display">\[\Delta = (\mathrm{tr}\, A)^2 - 4 \det A\]</span></p>
<p>the <strong>discriminant</strong> of the quadratic formula. The two eigenvalues of <span class="math inline">\(A\)</span> are real if and only if <span class="math inline">\(\Delta \geq 0\)</span>, i.e. <span class="math inline">\(\mathrm{tr}\, A)^2 \geq 4 \det A\)</span> Then we have the following properties:</p>
<ol type="1">
<li><span class="math inline">\(\Delta &lt; 0\)</span>, complex eigenvalues</li>
</ol>
<ul>
<li><p>The two eigenvalues are complex conjugate: <span class="math inline">\(\lambda_1 = \bar \lambda_2\)</span></p></li>
<li><p>Their real part <span class="math inline">\(\Re(\lambda) = \frac{1}{2} \mathrm{tr}\, A\)</span>.</p></li>
</ul>
<ol start="2" type="1">
<li><p><span class="math inline">\(\Delta = 0\)</span>, there is a single root of multiplicity 2: <span class="math inline">\(\lambda = \frac{1}{2} \mathrm{tr}\, A\)</span>.</p></li>
<li><p><span class="math inline">\(\Delta &gt; 0, \det A &gt; 0\)</span>, real, distinct eigenvalues of the same sign.</p></li>
</ol>
<ul>
<li><p><span class="math inline">\(\mathrm{tr}\, A &gt; 0\)</span> and <span class="math inline">\(\det A &gt; 0\)</span>. Then <span class="math inline">\(\lambda_{1,2}\)</span> are distinct and positive.</p></li>
<li><p><span class="math inline">\(\mathrm{tr}\, A &lt; 0\)</span> and <span class="math inline">\(\det A &gt; 0\)</span>. Then <span class="math inline">\(\lambda_{1,2}\)</span> are distinct and negative.</p></li>
</ul>
<ol start="4" type="1">
<li><span class="math inline">\(\det A &lt; 0\)</span>, real distinct eigenvalues of opposite sign.</li>
</ol>
<ul>
<li><span class="math inline">\(\lambda_1 &lt; 0 &lt; \lambda_2\)</span>.</li>
</ul>
<ol start="5" type="1">
<li><span class="math inline">\(\det A = 0\)</span> one of the eigenvalue is zero, the other eigenvalue is <span class="math inline">\(\mathrm{tr}\, A\)</span>.</li>
</ol>
<h3 id="exercises-on-eigenvalues">Exercises on eigenvalues</h3>
<p><strong>Exercise 7</strong> Properties of the eigenvalues of 2x2 matrices. For each 2x2 matrix, compute the determinant, the trace, and the discriminant, and determine whether the eigenvalues are real, complex, distinct, and the sign (negative, positive, or zero) of the real parts.</p>
<p><span class="math display">\[A_1 = \begin{pmatrix}
0 &amp; -1 \\
1 &amp;  0 
\end{pmatrix}, \quad
A_2 = \begin{pmatrix}
-2 &amp;  1 \\
 1 &amp; -2 
\end{pmatrix}, \quad
A_3 = \begin{pmatrix}
 1 &amp; -2 \\
 0 &amp;  1 
\end{pmatrix}, \quad
A_4 = \begin{pmatrix}
-1 &amp;  2 \\
1/2&amp;  2 
\end{pmatrix}.
\]</span></p>
<h2 id="matrix-vector-operations">Matrix-vector operations</h2>
<p>A matrix defines a linear transformation between vector spaces. Given a vector <span class="math inline">\(x\)</span>, the product <span class="math inline">\(Ax\)</span> is vector composed of linear combinations of the coefficients of <span class="math inline">\(x\)</span>. For a matrix 2x2, the vector <span class="math inline">\(x\)</span> must be a vector of size 2, and the product <span class="math inline">\(Ax\)</span> is a vector of size two. If <span class="math inline">\(x = (x_1, x2)^t\)</span> (the <span class="math inline">\({}^t\)</span> stands for the transpose, because <span class="math inline">\(x\)</span> must be a column vector), and <span class="math inline">\(A = [ a_{ij} ]_{i=1,2, \, j=,1,2}\)</span>, then</p>
<p><span class="math display">\[
Ax = 
\begin{pmatrix}
a_{11} &amp;  a_{12} \\
a_{21} &amp;  a_{22} 
\end{pmatrix}
\begin{pmatrix}
x_{1}  \\
x_{2}  
\end{pmatrix}
=
\begin{pmatrix}
a_{11} x_{1} + a_{12} x_2  \\
a_{21} x_{1} + a_{22} x_2 
\end{pmatrix}.
\]</span></p>
<p>Successive linear transformations can be accomplished by applying several matrices. Given two matrices <span class="math inline">\(A, B\)</span>, the matrix product <span class="math inline">\(C = AB\)</span> is also a matrix. The matrix <span class="math inline">\(C\)</span> is the linear transformation that first apply <span class="math inline">\(B\)</span>, then <span class="math inline">\(A\)</span>. Matrix product is <em>not</em> commutative is general: <span class="math inline">\(AB \neq BA\)</span>. <em>(If <span class="math inline">\(B\)</span> means ‘put on socks’ and <span class="math inline">\(A\)</span> means ‘put on shoes’, then <span class="math inline">\(BA\)</span> does not have the expected result.)</em> The product of two matrices <span class="math inline">\(A = [ a_{ij} ]_{i=1,2, \, j=,1,2}\)</span> and <span class="math inline">\(B = [ b_{ij} ]_{i=1,2, \, j=,1,2}\)</span> is</p>
<p><span class="math display">\[
AB = 
\begin{pmatrix}
a_{11} &amp;  a_{12} \\
a_{21} &amp;  a_{22} 
\end{pmatrix}
\begin{pmatrix}
b_{11} &amp;  b_{12} \\
b_{21} &amp;  b_{22} 
\end{pmatrix}
=
\begin{pmatrix}
a_{11} b_{11} + a_{12}b_{21} &amp; a_{11}b_{12} + a_{12}b_{22} \\
a_{21} b_{11} + a_{22}b_{21} &amp; a_{21}b_{12} + a_{22}b_{22}
\end{pmatrix}.
\]</span></p>
<p>The <strong>sum of two matrices</strong> <span class="math inline">\(A+B\)</span> is performed element-wise: <span class="math inline">\(A+B = [a_{ij} + b_{ij}]_{i=1,2, \, j=,1,2}\)</span>. The <strong>sum of two vectors</strong> is defined similarly. Addition is commutative.<br />
Matrix operations are associative and distributive.</p>
<p><span class="math display">\[\begin{align*}
A + B &amp; = B + A, \\
A(B + C) &amp; = AB + BC, \\
A(BC)  &amp; = (AB)C. 
\end{align*}\]</span></p>
<p>Matrices and vectors can be multiplied by a scalar value (real or complex). <strong>Multiplication by a scalar</strong> is associative, distributive, and commutative. The result of the multiplication by a scalar is to multiply each coefficient of the matrix or vector by the scalar. For example, if <span class="math inline">\(\lambda, \mu\)</span> are scalars,</p>
<p><span class="math display">\[\begin{align*}
\lambda A &amp; = A (\lambda I) = A \lambda, \\
\lambda ( A + B ) &amp; = \lambda A + \lambda B, \\
(\lambda A) B &amp; = \lambda (AB) = A (\lambda B), \\
(\mu + \lambda) A &amp; = \mu A + \lambda A, \\
\mu (\lambda A) &amp; = (\mu \lambda) A, ...
\end{align*}\]</span></p>
<p>The product between two column vectors is not defined, because the sizes do not match. However, we can define the <strong>scalar product</strong> between two column vectors the same way matrix product is defined <span class="math inline">\(x, y\)</span>:</p>
<p><span class="math display">\[x^ty = x_1 y_1 + x_2 y_2.\]</span></p>
<p>If the vectors are complex-valued, we need also to conjugate the transposed vector <span class="math inline">\(x^t\)</span>. The conjugate-transpose is called the <strong>adjoint</strong> and is denoted <span class="math inline">\({}^*\)</span>. Thus, if <span class="math inline">\(x\)</span> is complex-valued, the adjoint <span class="math inline">\(x^*\)</span> is the row vector <span class="math inline">\((\bar x_1, \bar x_2)\)</span>. The scalar product for complex-valued vectors is denoted <span class="math inline">\(x^*y\)</span>. Since this notation also works for real-valued vector, we will used most of the time.</p>
<h3 id="exercises-on-matrix-vector-and-matrix-matrix-operations">Exercises on Matrix-vector and matrix-matrix operations</h3>
<p><strong>Exercise 8</strong> Compute matrix-vector product <span class="math display">\[
\begin{pmatrix}
0 &amp; -1 \\
1 &amp;  0 
\end{pmatrix}
\begin{pmatrix}
x_1 \\ x_2
\end{pmatrix}.
\]</span> What is the transformation given by this matrix.</p>
<p><strong>Exercise 9</strong> Compute the matrix-matrix product <span class="math display">\[
\begin{pmatrix}
0 &amp; -1 \\
1 &amp;  0 
\end{pmatrix}
\begin{pmatrix}
1 &amp;  0 \\
0 &amp; -1 
\end{pmatrix}.
\]</span> Can you tell what transformation this is?</p>
<p><strong>Exercise 10</strong> Now compute the product of the same matrices, but in the inverse order <span class="math display">\[
\begin{pmatrix}
1 &amp;  0 \\
0 &amp; -1 
\end{pmatrix}
\begin{pmatrix}
0 &amp; -1 \\
1 &amp;  0 
\end{pmatrix}.
\]</span> Compare with the solution found in 9. What is this transformation?</p>
<p><strong>Exercise 11</strong> Find the matrix that takes a vector <span class="math inline">\(x = (x_1,x_2)^t\)</span> and returns <span class="math inline">\((a x_1, b x_2)^t\)</span>.</p>
<p><strong>Exercise 12</strong> Find the matrix that takes a vector <span class="math inline">\(x = (x_1,x_2)^t\)</span> and returns <span class="math inline">\((x_2, x_1)^t\)</span>.</p>
<p><strong>Exercise 13</strong> Find the matrix that takes a vector <span class="math inline">\(x = (x_1,x_2)^t\)</span> and returns <span class="math inline">\((x_2, 0)^t\)</span>.</p>
<p><strong>Exercise 14</strong> Compute the successive powers <span class="math inline">\(A, A^2, A^3, ...\)</span>, for a diagonal matrix <span class="math inline">\(A\)</span>:</p>
<p><span class="math display">\[
A =\begin{pmatrix}
a &amp;  0 \\
0 &amp;  b 
\end{pmatrix}
\]</span></p>
<p><strong>Exercise 15</strong> Compute the scalar product between <span class="math inline">\(x = (1 + 2i, 1 - i)^t\)</span> and <span class="math inline">\(y = (0.5 - i, -0.5)^t\)</span>.</p>
<p><strong>Exercise 16</strong> Now compute the scalar product <span class="math inline">\(y^*x\)</span> and compare with the result in 8.7.</p>
<p><strong>Exercise 17</strong> Compute the scalar product between <span class="math inline">\(z = (z_1, z_2)^t\)</span> and itself, if <span class="math inline">\(z\)</span> is a complex-valued vector. What can you say about the result?</p>
<hr />
<p><strong>Tips on eigenvalues</strong> Some matrices have special shapes that make it easier to compute the determinant, and the eigenvalues. These are called eigenvalue-revealing shapes.</p>
<ul>
<li><p>Diagonal matrices have their eigenvalues on the diagonal.</p></li>
<li><p><strong>Triangular matrices</strong>, i.e. matrices that have zeros above (lower-triangular matrix) or below (upper-triangular matrix) the main diagonal have also their eigenvalues on the diagonal.</p></li>
<li><p>A matrix with a row or a column of zeros has its determinant equal to zero. This implies that one of its eigenvalues is 0.</p></li>
</ul>
<hr />
<h2 id="eigenvalue-decomposition">Eigenvalue decomposition</h2>
<p>In many applications, it is useful to decompose a matrix into a form that makes it easier to operate complex operations on. For instance, we might want to compute the powers of a matrix <span class="math inline">\(A\)</span>: <span class="math inline">\(A^2\)</span>, <span class="math inline">\(A^3\)</span>, <span class="math inline">\(A^4\)</span>. Multiplying matrices are computationally intensive, especially when the size of the matrix becomes large. The <strong>power of a matrix</strong> is <span class="math inline">\(A^k = AA...A\)</span>, <span class="math inline">\(k\)</span> times. The zeroth power is the identity matrix: <span class="math inline">\(A^0 = I\)</span>.</p>
<p>The <strong>inverse</strong> of a matrix <span class="math inline">\(A\)</span>, denoted by <span class="math inline">\(A^{-1}\)</span> is the unique matrix such that <span class="math inline">\(AA^{-1} A{^-1}A = I\)</span>. The notation is self-consistent with the positive powers of <span class="math inline">\(A\)</span>. The inverse does not always exist. A matrix is <strong>invertible</strong> if and only if its determinant is not 0. If <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are invertible, then <span class="math inline">\(AB\)</span> is invertible, and <span class="math inline">\((AB)^{-1} = B^{-1}A^{-1}\)</span>.</p>
<p>The <strong>eigenvalue decomposition</strong> is a decomposition of the form <span class="math inline">\(A = X D X^{-1}\)</span>, where <span class="math inline">\(D\)</span> is a diagonal matrix, and <span class="math inline">\(X\)</span> is an invertible matrix. If there exists such a decomposition for <span class="math inline">\(A\)</span>, then computing powers of <span class="math inline">\(A\)</span> becomes easy:</p>
<p><span class="math display">\[\begin{align*}
A^k &amp; = (XDX^{-1})^k = XDX^{-1} \, XDX^{-1} \, ... XDX^{-1}, \\
    &amp; = XD(X^{-1}X)D(X^{-1}X) D ... (X^{-1}X) DX^{-1},
    &amp; = XD^kX^{-1}.
\end{align*}\]</span></p>
<p>The eigenvalue decomposition does not always exists, because it is not always possible to find an invertible matrix <span class="math inline">\(X\)</span>. When it exists, though, the columns of the matrix <span class="math inline">\(X\)</span> is composed of the eigenvectors of <span class="math inline">\(A\)</span>. When <span class="math inline">\(A\)</span> is a 2x2 matrix, it is enough to find 2 linearly independent eigenvectors <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span> for the matrix</p>
<p><span class="math display">\[X = \Biggl( \begin{array}{c|c} x_1 &amp; y_1 \\ x_2 &amp; y_2 \end{array} \Biggr)\]</span></p>
<p>to be invertible.</p>
<h2 id="eigenvectors">Eigenvectors</h2>
<p>The <strong>eigenvectors</strong> of a matrix <span class="math inline">\(A\)</span> are the <em>nonzero</em> vectors <span class="math inline">\(x\)</span> such that for an eigenvalue <span class="math inline">\(\lambda\)</span> of <span class="math inline">\(A\)</span>,</p>
<p><span class="math display">\[Ax = \lambda x.\]</span></p>
<p>If <span class="math inline">\(x\)</span> is an eigenvector, so is any <span class="math inline">\(\alpha x\)</span> for any scalar value <span class="math inline">\(\alpha\)</span>. If there are two linearly independent eigenvectors <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span> associated to an eigenvalue, <span class="math inline">\(\alpha x + \beta y\)</span> is also an eigenvector. There is at least one eigenvector for each distinct eigenvalue, but there may be more than one when the eigenvalue is repeated.</p>
<h3 id="example-1-distinct-real-eigenvalues">Example 1 Distinct, real eigenvalues</h3>
<p>The matrix</p>
<p><span class="math display">\[
A =\begin{pmatrix}
-1 &amp; -2 \\
0  &amp;  1 
\end{pmatrix}
\]</span></p>
<p>is upper-triangular; this is one of the eigenvalue-relealing shapes. The eigenvalues are <span class="math inline">\(-1\)</span> and <span class="math inline">\(1\)</span>. These are distinct eigenvalues, so each eigenvalue possesses a single eigenvector. The eigenvector <span class="math inline">\(x\)</span> associated to <span class="math inline">\(\lambda_1 = -1\)</span> is found by solving the eigensystem</p>
<p><span class="math display">\[Ax = (-1)x.\]</span></p>
<p>The unknown quantity <span class="math inline">\(x\)</span> appears on both sides of the equation. We can find a simpler form by noting that multiplying a vector by the identity matrix is neutral: <span class="math inline">\((-1)x = (-1) I x.\)</span> The eigenproblem becomes</p>
<p><span class="math display">\[\begin{align*}
A x &amp; = (-1) I x, \\
A x - (-1) I x = 0, \\
\bigl( A - (-1) I \bigr) x = 0,
\end{align*}\]</span></p>
<p>that is, the eigenvector is a nonzero solution of the linear system <span class="math inline">\(\bigl( A - \lambda I \bigr) x = 0\)</span>. In general, if a matrix <span class="math inline">\(B\)</span> is invertible, the only solution to <span class="math inline">\(Bx=0\)</span> is <span class="math inline">\(x = 0\)</span> (the vector of zeroes). But, by construction, <span class="math inline">\(A - \lambda I\)</span> cannot be invertible if <span class="math inline">\(\lambda\)</span> is an eigenvalue: its determinant is exactly the characteristic polynomial evaluated at one of its roots, so it is zero. This is why the eigensystem has nonzero solutions. Now, because <span class="math inline">\(A - \lambda I\)</span> is not invertible, this means that a least one of its rows is a linear combination of the others. For 2x2 matrices, this implies that the two rows are colinear, or redundant. For our example, the eigensystem reads</p>
<p><span class="math display">\[\begin{align*}
\begin{pmatrix}
-1 - (-1) &amp; -2 \\
0  &amp;  1 - (-1) 
\end{pmatrix}
\begin{pmatrix}
x_1  \\
x_2  \\
\end{pmatrix}
 &amp; = 
\begin{pmatrix}
0  \\
0  \\
\end{pmatrix}, \\ 
\begin{pmatrix}
0  &amp; -2 \\
0  &amp;  2 
\end{pmatrix}
\begin{pmatrix}
x_1  \\
x_2  \\
\end{pmatrix}
 &amp; = 
\begin{pmatrix}
0  \\
0  \\
\end{pmatrix}.
\end{align*}\]</span></p>
<p>we immediately see that the two rows <span class="math inline">\((0,-2)\)</span> and <span class="math inline">\((0,2)\)</span> are colinear, with a factor <span class="math inline">\(-1\)</span>. This leads to an underdetermined system: <span class="math inline">\(0 x_1 + -2 x_2 = 0\)</span>. The solution is <span class="math inline">\(x_2 = 0\)</span> and we can take <span class="math inline">\(x_1\)</span> to be any value, save 0. We choose <span class="math inline">\(x = (1, 0)^t\)</span>.</p>
<p>For the eigenvalue <span class="math inline">\(\lambda_2 = +1\)</span>, the eigensystem reads:</p>
<p><span class="math display">\[\begin{align*}
\begin{pmatrix}
-1 - (+1) &amp; -2 \\
0  &amp;  1 - (+1) 
\end{pmatrix}
\begin{pmatrix}
y_1  \\
y_2  \\
\end{pmatrix}
 &amp; = 
\begin{pmatrix}
0  \\
0  \\
\end{pmatrix}, \\ 
\begin{pmatrix}
-2  &amp; -2 \\
0  &amp;   0
\end{pmatrix}
\begin{pmatrix}
y_1  \\
y_2  \\
\end{pmatrix}
 &amp; = 
\begin{pmatrix}
0  \\
0  \\
\end{pmatrix}.
\end{align*}\]</span></p>
<p>Again, the second row <span class="math inline">\((0,0)\)</span> can be neglected, and the solution is <span class="math inline">\(-2 y_1 + 2 y_2 = 0\)</span>, or <span class="math inline">\(y_1 = y_2\)</span>. It is customary to choose an eigenvector with norm 1. The <strong>norm</strong> of a complex-valued vector <span class="math inline">\(y = (y_1, y_2)^t\)</span> is</p>
<p><span class="math display">\[||y|| = \sqrt{y^*y} = \sqrt{\bar y_1 y_1 + \bar y_2 y_2} = \sqrt{|y_1|^2 + |y_2|^2}.\]</span></p>
<p>Here, the eigenvector is <span class="math inline">\(y = (y_1, y_1)^t\)</span>, so <span class="math inline">\(||y|| = \sqrt{|y_1|^2 + |y_1|^2} = \sqrt{2}\sqrt{|y_1|^2} = \sqrt{2}|y_1|.\)</span> Taking <span class="math inline">\(||y|| = 1\)</span> solves <span class="math inline">\(|y_1| = 1/\sqrt{2}.\)</span> This means that we could take a negative, or a complex value for <span class="math inline">\(y_1\)</span>, as long as the <span class="math inline">\(|y_1| = 1/\sqrt{2}.\)</span> Going for simplicity, we take <span class="math inline">\(y_1 = 1/\sqrt{2}\)</span>.</p>
<h3 id="example-2-complex-eigenvalues">Example 2 Complex eigenvalues</h3>
<p>The matrix</p>
<p><span class="math display">\[
A =\begin{pmatrix}
0  &amp; -1 \\
1  &amp;  0 
\end{pmatrix}
\]</span></p>
<p>is <em>not</em> diagonal, so we have to compute the eigenvalues by hand. The trace of <span class="math inline">\(A\)</span> is zero, the determinant is <span class="math inline">\(0 - (1)(-1) = 1\)</span>, and the discriminant is <span class="math inline">\(-4\)</span>. A negative discriminant implies complex eigenvalues,</p>
<p><span class="math display">\[\lambda_{1,2} = \frac 12 \bigl( 0 \pm \sqrt{-4} \bigr) = \pm i.\]</span></p>
<p>For the eigenvalue <span class="math inline">\(\lambda_1 = +i\)</span>, the eigensystem reads:</p>
<p><span class="math display">\[\begin{align*}
\begin{pmatrix}
- (+i) &amp;  -1 \\
1      &amp;  - (+i) 
\end{pmatrix}
\begin{pmatrix}
x_1  \\
x_2  \\
\end{pmatrix}
 &amp; = 
\begin{pmatrix}
0  \\
0  \\
\end{pmatrix}, \\ 
\begin{pmatrix}
-i  &amp; -1 \\
1  &amp;  -i
\end{pmatrix}
\begin{pmatrix}
x_1  \\
x_2  \\
\end{pmatrix}
 &amp; = 
\begin{pmatrix}
0  \\
0  \\
\end{pmatrix}.
\end{align*}\]</span></p>
<p>The two rows <span class="math inline">\((-i,1)\)</span> and <span class="math inline">\((1,-i)\)</span> should be colinear, but this is not obvious with the complex coefficients. Multiplying the first row by <span class="math inline">\(i\)</span> gives <span class="math inline">\(i(-i, -1) = (- i^2, - i) = (-(-1), -i) = (1, -i)\)</span>, the second row, ok. Having confirmed that the system is indeed underdetermined, we can week a solution to <span class="math inline">\(-i x_1 - x_2 = 0\)</span>. Solving for <span class="math inline">\(x_2 = -i x_1\)</span>, we obtain the eigenvector <span class="math inline">\(x = (x_1, -i x_2)^t\)</span>. Normalization of <span class="math inline">\(x\)</span> imposes</p>
<p><span class="math display">\[||x|| = \sqrt{|x_1|^2 + |-ix_1|^2} = \sqrt{|x_1|^2 + |x_1|^2} = \sqrt{2}|x_1| = 1.\]</span></p>
<p>As in the previous example, we can choose <span class="math inline">\(x_1 = 1/\sqrt{2}.\)</span></p>
<p>The second eigenvectors, associated <span class="math inline">\(\lambda_2 = -i\)</span>, solves the eigensystem</p>
<p><span class="math display">\[\begin{align*}
\begin{pmatrix}
- (-i) &amp;  -1 \\
1      &amp;  - (-i) 
\end{pmatrix}
\begin{pmatrix}
y_1  \\
y_2  \\
\end{pmatrix}
 &amp; = 
\begin{pmatrix}
0  \\
0  \\
\end{pmatrix}, \\ 
\begin{pmatrix}
i  &amp; -1 \\
1  &amp;  i
\end{pmatrix}
\begin{pmatrix}
y_1  \\
y_2  \\
\end{pmatrix}
 &amp; = 
\begin{pmatrix}
0  \\
0  \\
\end{pmatrix}.
\end{align*}\]</span></p>
<p>The first row yields <span class="math inline">\(iy_1 - y_2 = 0\)</span>, so <span class="math inline">\(y = (y_1, iy_2)^t\)</span>. A normalized eigenvector can be <span class="math inline">\(y = (1/\sqrt{2}, i/\sqrt{2})^t\)</span>. We could also have chosen <span class="math inline">\(y = (i/\sqrt{2}, -1/\sqrt{2})^t\)</span>.</p>
<h3 id="example-3-repeated-eigenvalues-1">Example 3 Repeated eigenvalues 1</h3>
<p>The matrix</p>
<p><span class="math display">\[
\begin{pmatrix}
-1  &amp;   0 \\
 2  &amp;  -1 
\end{pmatrix}
\]</span></p>
<p>is lower-trianglar, with repeated eigenvalues on the diagonal, <span class="math inline">\(\lambda_{1,2} = -1\)</span>. The eigenvectors associated with <span class="math inline">\(-1\)</span> satisfy the eigenproblem</p>
<p><span class="math display">\[\begin{align*}
\begin{pmatrix}
-1 - (-1) &amp;  0 \\
 2      &amp;  -1 - (-1) 
\end{pmatrix}
\begin{pmatrix}
x_1  \\
x_2  \\
\end{pmatrix}
 &amp; = 
\begin{pmatrix}
0  \\
0  \\
\end{pmatrix}, \\ 
\begin{pmatrix}
 0  &amp;  0 \\
 2 &amp;   0
\end{pmatrix}
\begin{pmatrix}
x_1  \\
x_2  \\
\end{pmatrix}
 &amp; = 
\begin{pmatrix}
0  \\
0  \\
\end{pmatrix}.
\end{align*}\]</span></p>
<p>The first row vanishes, and the second row means that <span class="math inline">\(x_1 = 0\)</span>, leaving for instance <span class="math inline">\(x_2 = 1\)</span>, and <span class="math inline">\(x = (0,1)^t\)</span>. There are no other linearly independent eigenvectors. This is not always the case, repeated eigenvalues can have more than one independent eigenvector, as in the next example.</p>
<h3 id="example-4-repeated-eigenvalues-2">Example 4 Repeated eigenvalues 2</h3>
<p>The matrix</p>
<p><span class="math display">\[
\begin{pmatrix}
-1  &amp;   0 \\
 0  &amp;  -1 
\end{pmatrix}
\]</span></p>
<p>is diagonal, with repeated eigenvalues on the diagonal, <span class="math inline">\(\lambda_{1,2} = -1\)</span>. The eigenvectors associated with <span class="math inline">\(-1\)</span> satisfy the eigenproblem</p>
<p><span class="math display">\[\begin{align*}
\begin{pmatrix}
-1 - (-1) &amp;  0 \\
 0      &amp;  -1 - (-1) 
\end{pmatrix}
\begin{pmatrix}
x_1  \\
x_2  \\
\end{pmatrix}
 &amp; = 
\begin{pmatrix}
0  \\
0  \\
\end{pmatrix}, \\ 
\begin{pmatrix}
 0  &amp;  0 \\
 0 &amp;   0
\end{pmatrix}
\begin{pmatrix}
x_1  \\
x_2  \\
\end{pmatrix}
 &amp; = 
\begin{pmatrix}
0  \\
0  \\
\end{pmatrix}.
\end{align*}\]</span></p>
<p>Now, the two rows vanished, leaving no condition at all on <span class="math inline">\(x_1\)</span> and <span class="math inline">\(x_2\)</span>. This means that all the vectors are eigenvectors! How many linearly independent eigenvectors can we find? Vectors of size 2 live in a vector space of dimension 2; we can find at most 2 linearly independent vectors. We can choose for instance the canonical basis: <span class="math inline">\(x = (1,0)^t\)</span> and <span class="math inline">\(y = (0,1)^t\)</span>.</p>
<hr />
<p><strong>Tips for eigenvalue decomposition</strong></p>
<ul>
<li><p>A 2x2 matrix (or any square matrix) admits an eigenvalue decomposition if all the eigenvalues are distinct. For 2x2 matrices, eigenvalues are distinct if and only if the discriminant <span class="math inline">\(\Delta \neq 0\)</span>.</p></li>
<li><p>If the matrix has a repeated eigenvalue, it will admit an eigenvalue decomposition if the number of (linearly independent) eigenvectors is equal to the number of times the eigenvalue is repeated. The number of eigenvectors is called geometric multiplicity, and the number of repeats is called algebraic multiplicity.</p></li>
<li><p>The eigenproblem should be underdetermined; you should always be able to eliminate at least one row by linear combination. If you cannot, this means that there is a error, possibly an incorrect eigenvalue, or a arithmetic mistake in computing <span class="math inline">\(A - \lambda I\)</span>.</p></li>
<li><p>Because eigenvalues are in general complex, the eigenvectors will also be complex.</p></li>
</ul>
<hr />
<h2 id="exercises-on-eigenvalues-decomposition">Exercises on eigenvalues decomposition</h2>
<h1 id="glossary">Glossary</h1>
<table>
<thead>
<tr class="header">
<th style="text-align: left;">French</th>
<th style="text-align: left;">English</th>
<th style="text-align: left;">Note</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">rang</td>
<td style="text-align: left;">rank</td>
<td style="text-align: left;"></td>
</tr>
<tr class="even">
<td style="text-align: left;">noyau</td>
<td style="text-align: left;">kernel</td>
<td style="text-align: left;">notation: <span class="math inline">\(\ker\)</span></td>
</tr>
<tr class="odd">
<td style="text-align: left;">ensemble</td>
<td style="text-align: left;">set</td>
<td style="text-align: left;"></td>
</tr>
<tr class="even">
<td style="text-align: left;">espace vectoriel</td>
<td style="text-align: left;">vector space</td>
<td style="text-align: left;"></td>
</tr>
<tr class="odd">
<td style="text-align: left;">sous-espace vectoriel</td>
<td style="text-align: left;">linear subspace</td>
<td style="text-align: left;"></td>
</tr>
<tr class="even">
<td style="text-align: left;">valeur propre</td>
<td style="text-align: left;">eigenvalue</td>
<td style="text-align: left;"></td>
</tr>
<tr class="odd">
<td style="text-align: left;">vecteur propre</td>
<td style="text-align: left;">eigenvector</td>
<td style="text-align: left;"></td>
</tr>
<tr class="even">
<td style="text-align: left;">sous-espace propre</td>
<td style="text-align: left;">eigenspace</td>
<td style="text-align: left;"></td>
</tr>
<tr class="odd">
<td style="text-align: left;">décomposition en valeurs propres</td>
<td style="text-align: left;">eigenvalue decomposition</td>
<td style="text-align: left;"></td>
</tr>
<tr class="even">
<td style="text-align: left;">décomposition en valeurs singulières</td>
<td style="text-align: left;">singular value decomposition</td>
<td style="text-align: left;"></td>
</tr>
<tr class="odd">
<td style="text-align: left;">valeur singulière</td>
<td style="text-align: left;">singular value</td>
<td style="text-align: left;"></td>
</tr>
<tr class="even">
<td style="text-align: left;">trace</td>
<td style="text-align: left;">trace</td>
<td style="text-align: left;"></td>
</tr>
<tr class="odd">
<td style="text-align: left;">déterminant</td>
<td style="text-align: left;">determinant</td>
<td style="text-align: left;"><span class="math inline">\(\det\)</span></td>
</tr>
<tr class="even">
<td style="text-align: left;">base</td>
<td style="text-align: left;">basis</td>
<td style="text-align: left;"></td>
</tr>
<tr class="odd">
<td style="text-align: left;">application linéaire</td>
<td style="text-align: left;">linear map</td>
<td style="text-align: left;"></td>
</tr>
<tr class="even">
<td style="text-align: left;">dimension</td>
<td style="text-align: left;">dimension</td>
<td style="text-align: left;"></td>
</tr>
<tr class="odd">
<td style="text-align: left;">moindres carrés</td>
<td style="text-align: left;">least-squares</td>
<td style="text-align: left;"></td>
</tr>
<tr class="even">
<td style="text-align: left;">produit scalaire</td>
<td style="text-align: left;">scalar product</td>
<td style="text-align: left;"></td>
</tr>
<tr class="odd">
<td style="text-align: left;">Vect</td>
<td style="text-align: left;">Span</td>
<td style="text-align: left;"></td>
</tr>
<tr class="even">
<td style="text-align: left;">famille libre</td>
<td style="text-align: left;">linearly independent set</td>
<td style="text-align: left;"></td>
</tr>
<tr class="odd">
<td style="text-align: left;">famille génératrice</td>
<td style="text-align: left;">spanning set</td>
<td style="text-align: left;"></td>
</tr>
</tbody>
</table>
<section class="footnotes" role="doc-endnotes">
<hr />
<ol>
<li id="fn1" role="doc-endnote"><p><a href="mailto:bernard@math.univ-lyon1.fr">bernard@math.univ-lyon1.fr</a><a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2" role="doc-endnote"><p><a href="mailto:pujo@math.univ-lyon1.fr">pujo@math.univ-lyon1.fr</a><a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>
</body>
</html>
